{
 "metadata": {
  "name": "",
  "signature": "sha256:14f1990ef7e7ec8d387404eca8be56cf8f2af583b4e410314d88c579e8cab1bf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Project Benefits Top Keywords - using RAKE\n",
      "Using:https://github.com/aneesha/RAKE\n",
      "\n",
      "The question:\n",
      "\n",
      "* _To do this properly we need a better understanding of what community benefit is. We think there could be some insights on this in the project descriptions._\n",
      "\n",
      "\n",
      "In this notebook we will:\n",
      "* Perform keyword extraction on The Key survey data (grouping columns by relevant problem).\n",
      "* Output as html and CSVs that can be imported into Gephi for graph plotting.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# preliminaries to make this work on my laptop - Change paths here to where you downloaded your rake fork.\n",
      "import sys,os\n",
      "RAKEPATH='C:\\\\bohana\\\\python\\\\RAKE\\\\RAKE-master'\n",
      "sys.path.append(RAKEPATH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below will load one col from The Key csv (REC_TO_LOAD) and pass it on to RAKE to get key words. I generated the CSV using The Key's dataset provided to the data dive, which includes an anonymized version of their survey data. \n",
      "\n",
      "Here's the query:\n",
      "```\n",
      "select gp._id, \n",
      "       kfs.name \"Fund Stage\", \n",
      "       s.name \"Stage\", \n",
      "       gpt.group_project_description,\n",
      "       gpt.panel_description,\n",
      "       -- Impact/benefit\n",
      "       gpt.facilitator_how_group_benefitted, \n",
      "       gpt.facilitator_eval_summary,\n",
      "       gpt.panel_how_young_people_change,\n",
      "       gpt.panel_new_experiences,\n",
      "       gpt.panel_how_benefitted,\n",
      "       -- Issues, Challenges\n",
      "       gpt.conflict_explanation,\n",
      "       gpt.issue_tackled,\n",
      "       gpt.other_factors\n",
      "from group_project gp,\n",
      "     key_fund_stage_lk kfs,\n",
      "     stage_lk s,\n",
      "     group_project_free_text_anon gpt\n",
      "where\n",
      "     gp.stage_id = s._id\n",
      " and gp._id = gpt.group_project_id\n",
      " and gp.key_fund_stage_id = kfs._id \n",
      " and s.name in ('Complete');\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import rake\n",
      "import nltk\n",
      "\n",
      "###\n",
      "#\n",
      "# Tunable parameters\n",
      "#\n",
      "##\n",
      "\n",
      "# these are stopwords for the key - not very informative in this domain\n",
      "KEY_STOP = set(['young','people', 'key', 'fund', 'keyfund', 'amazing', 'huge', 'fantastic', 'na', 'n/a', 'xxxx'])\n",
      "\n",
      "# Score threshold which RAKE will use\n",
      "SCORE_THRESHOLD=1.0\n",
      "\n",
      "# This is the column grouping in the CSV that we're insterested in\n",
      "#REC_TO_LOAD=[3,4] # Project description\n",
      "#REC_TO_LOAD=[10,11,12] ## Issues / Challenges\n",
      "REC_TO_LOAD=[5,6,7,8,9] ## Benefits / Impact\n",
      "\n",
      "# Top K thresholds to retrieve\n",
      "TOPK=20      # used to generate HTML output in the notebook\n",
      "TOPKCSV=200  # broader list to go into graph plotting\n",
      "\n",
      "SOURCECSV='C:\\\\bohana\\\\edu\\\\datakind\\\\anon\\\\prod\\\\mv_impact_stage.csv'\n",
      "#\n",
      "# ##########################################################\n",
      "#\n",
      "\n",
      "\n",
      "def sanitize(instring):\n",
      "    ''' \n",
      "       removes unwanted stuff from our string, does some basic preprocessing\n",
      "    '''\n",
      "    tokens=nltk.word_tokenize(instring.lower())\n",
      "    return ' '.join([t for t in tokens if t not in KEY_STOP])\n",
      "\n",
      "# Create a rake obj\n",
      "rk = rake.Rake(os.path.join(RAKEPATH,'SmartStoplist.txt'))\n",
      "\n",
      "# prepare csv to load\n",
      "file = open(SOURCECSV, 'rb')\n",
      "csvr = csv.reader(file)\n",
      "textoutput = ''\n",
      "\n",
      "# we now have keywords by stage\n",
      "keywords = {'Stage 1': [],\n",
      "            'Stage 2': [],\n",
      "            'Stage 3': [],\n",
      "            'Stage 4': []}\n",
      "# iterave csv loading keywords extracted from each set of cols per REC_TO_LOAD\n",
      "# and \n",
      "for records in csvr:\n",
      "    thisstage=records[1]\n",
      "    thisrec=' '.join([records[i] for i in REC_TO_LOAD])\n",
      "    thisrec=thisrec.decode(errors='ignore')\n",
      "    textoutput=sanitize(thisrec)\n",
      "    if thisstage in keywords.keys():\n",
      "        kw = rk.run(textoutput)\n",
      "        keywords[thisstage].append(kw)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 235
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Find most frequent keywords\n",
      "After calculating keywords for each doc, add the most common ones into a counter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find most frequent keywords\n",
      "import collections\n",
      "c = {\n",
      "  'Stage 1': collections.Counter(),\n",
      "  'Stage 2': collections.Counter(),\n",
      "  'Stage 3': collections.Counter(),\n",
      "  'Stage 4': collections.Counter()\n",
      "}\n",
      "\n",
      "# keywords contains lists of tuples (keyword, score) found in each document\n",
      "for stage in c.keys():\n",
      "    for kw in keywords[stage]:\n",
      "        # in a stage, we have a list of lists (keyword tuples)\n",
      "        for k in kw:\n",
      "            if type(k) is not list: k=[k]\n",
      "            # here we have a list of tuples\n",
      "            c[stage].update([x[0] for x in k if x[1] >= SCORE_THRESHOLD])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "# Generate a sample report with the keywords\n",
      "#\n",
      "htmlout=''\n",
      "htmlout += '<h1>Top Keywords by Project Stage</h1><p><i>All projects are in stage \"completed\"</i>'\n",
      "\n",
      "for s in sorted(c.keys()):\n",
      "    htmlout += '<br><h3>'+s+'</h3>'\n",
      "    topkeys =  c[s].most_common(TOPK)\n",
      "    htmlout += '<ul>'+' '.join(['<li>'+x[0]+'</li>' for x in topkeys])+'</ul>'\n",
      "    \n",
      "# ipython notebook magic to dump html into the notebook\n",
      "# uncomment next line to get output in the notebook\n",
      "get_ipython().run_cell_magic(u'HTML', u'something', htmlout)\n",
      "\n",
      "#\n",
      "# gephi graph generation\n",
      "#\n",
      "f = open('c:\\\\temp\\\\keyout_edges.csv','w')\n",
      "f.write('Source,Target,Weight\\n')\n",
      "nodes=[]\n",
      "nodescount=0\n",
      "for s in sorted(c.keys()):\n",
      "    nodes.append((s,s,'stage'))\n",
      "    nodescount+=1\n",
      "    topkeys = c[s].most_common(TOPKCSV)\n",
      "    for k in topkeys:\n",
      "        nodes.append((k[0],k[0],'keyword'))\n",
      "        nodescount+=1\n",
      "        f.write(','.join([s,k[0],str(k[1])])+'\\n')\n",
      "\n",
      "f.close()\n",
      "# Generate a nodes list for gephi\n",
      "f = open('c:\\\\temp\\\\keyout_nodes.csv','w')\n",
      "f.write('id,label,category\\n')\n",
      "for node in nodes:\n",
      "    f.write(','.join([node[0], node[1], node[2]])+'\\n')\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    }
   ],
   "metadata": {}
  }
 ]
}